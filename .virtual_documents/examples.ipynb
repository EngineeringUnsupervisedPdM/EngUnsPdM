





import methods
import pandas as pd
from matplotlib import pyplot as plt






def plotrow(row,color):
    plt.plot(row,color=color)
def plotmanyrows(rows,color):
    for row in rows:
        plotrow(row,color)









df=pd.read_csv("CaseStudyData/Episode2.csv",index_col=0)
df.head(3)



plotrow(df.values[0],color="blue")
plotrow(df.values[-1],color="red")
plt.show()





df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)

plotrow(df.values[0],color="blue")
plotrow(df.values[-1],color="red")
plt.show()





# apply profilebase algorithm
# We choose Selftuning technique to calculate threshold and window_ma=30 for smoothing the anomaly scores.
# Moreover by defaulr (LimitMaxdist = None) we choose the automatic proccess of profile calculation.
# the execution time is depending on choice of distance metric
anomalyscores,threshold=methods.profileBased(df,metric="euclidean",profileSize=60,factor=7,window_ma=30)

plt.plot(anomalyscores)
plt.axhline(threshold,color="red")
plt.show()








anomalyscores,threshold=methods.profileBased(df,metric="cc",profileSize=60,factor=14,window_ma=30)

plt.plot(anomalyscores)
plt.axhline(threshold,color="red")
plt.show()






anomalyscores,threshold=methods.profileBased(df,metric="euclidean",profileSize=60,factor=0.4,window_ma=30,thresholdTec="MaxInnerDistance")

plt.plot(anomalyscores)
plt.axhline(threshold,color="red")
plt.show()





profile_df=pd.read_csv("datasamples/ExternalProfil.csv",index_col=0)
# as previously performing a nomralization for each row
profile_df = profile_df.sub(profile_df.min(axis=1), axis=0).div(profile_df.max(axis=1) - profile_df.min(axis=1), axis=0)

# we plot the first row of the episode data and the Reference profile data
plotmanyrows(profile_df.values,"blue")
plt.plot(df.values[0],color="red")
plt.show()






# run profile based with external profile.
anomalyscores,threshold=methods.profileBasedRef(df,profile_df,metric="euclidean",profileSize=60,factor=2,window_ma=30)
plt.plot(anomalyscores)
plt.axhline(threshold,color="red")
plt.show()





# suposed that an event of interest took place a time 400, 
# where we wanted the algorithm to reset and recalculate the profile.
# In that case we can use the profileBasedWithResets to simulate it.
Resets=[400]


allerrors,allindexes,allthresholds=methods.profileBasedWithResets(df,Resets,metric="euclidean",profileSize=60,factor=2,window_ma=30,thresholdTec="SelfTuning",LimitMaxdist = None)

plt.plot(allindexes,allerrors)
plt.plot(allindexes,allthresholds,color="red")
plt.show()





# minmaxnormilization indicates whether we want to perform MinMax normilazation to data. 
# if historicDf is given then the features are calculated also to these data and min and 
#      max are calculated to be used for the normilization.
# (default) if if historicDf is None then the min max normalization is performed using min max of episode data.
df=pd.read_csv("CaseStudyData/Episode2.csv",index_col=0)

dfFeats=methods.calculateFeatures(df,historicDf=None,minmaxnormilization=True)

anomalyscores,threshold=methods.profileBased(dfFeats,metric="euclidean",profileSize=60,factor=6.5,window_ma=30)

plt.plot(anomalyscores)
plt.axhline(threshold,color="red")
plt.show()





import methods
import pandas as pd
from matplotlib import pyplot as plt





df=pd.read_csv("CaseStudyData/Episode1.csv",index_col=0)
df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)

anomalyscores,threshold=methods.PdM_Tranad(df,profileSize=100,factor=2,window_ma=30,epochs=10)

plt.plot(anomalyscores)
plt.plot(threshold,color="red")
plt.show()





import evaluation
import methods
import pandas as pd
from matplotlib import pyplot as plt






df2=pd.read_csv("CaseStudyData/Episode1.csv",index_col=0)
df2 = df2.sub(df2.min(axis=1), axis=0).div(df2.max(axis=1) - df2.min(axis=1), axis=0)

df=pd.read_csv("CaseStudyData/Episode2.csv",index_col=0)
df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)


predictions=[]
thresholds=[]
for episodedf in [df,df2]:
    anomalyscores,threshold=methods.profileBased(episodedf,metric="cc",profileSize=60,factor=10,window_ma=30)
    predictions.append(anomalyscores)
    thresholds.append(threshold)








recall,Precision,fbeta,axes=evaluation.myeval(predictions,thresholds,PH="300",lead="30")
plt.show()

print(f"F1: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")





recall,Precision,fbeta,axes=evaluation.myeval(predictions,0.0001,PH="100",lead="20")
plt.show()
print(f"F1: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")





recall,Precision,fbeta,axes=evaluation.myeval(predictions,thresholds,PH="300",lead="30",beta=2)
plt.show()

print(f"F2: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")





ingoreperiods=[(1200,1400)]

recall,Precision,fbeta,axes=evaluation.myeval(predictions,thresholds,PH="300",lead="30",beta=2,ignoredates=ingoreperiods)
plt.show()

print(f"F2: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")





import evaluation
import methods
import pandas as pd
from matplotlib import pyplot as plt


df2=pd.read_csv("CaseStudyData/Episode1.csv",index_col=0)
df2 = df2.sub(df2.min(axis=1), axis=0).div(df2.max(axis=1) - df2.min(axis=1), axis=0)

df=pd.read_csv("CaseStudyData/Episode2.csv",index_col=0)
df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)

df3=pd.read_csv("CaseStudyData/Episode8.csv",index_col=0)
df3 = df3.sub(df3.min(axis=1), axis=0).div(df3.max(axis=1) - df3.min(axis=1), axis=0)

df4=pd.read_csv("CaseStudyData/Episode9.csv",index_col=0)
df4 = df4.sub(df4.min(axis=1), axis=0).div(df4.max(axis=1) - df4.min(axis=1), axis=0)



predictions=[]
thresholds=[]
for episodedf in [df,df2,df3,df4]:
    anomalyscores,threshold=methods.PdM_Tranad(episodedf,profileSize=60,factor=3,window_ma=30,epochs=10)
    predictions.append(anomalyscores)
    thresholds.append(threshold)




recall,Precision,fbeta,axes=evaluation.myeval(predictions,thresholds,PH="300",lead="30",beta=1,ignoredates=ingoreperiods)
plt.show()
print(f"F2: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")





import methods
import pandas as pd
from matplotlib import pyplot as plt






import os
import sys
from fbprophet import Prophet


# from https://stackoverflow.com/questions/11130156/suppress-stdout-stderr-print-from-python-functions
class suppress_stdout_stderr(object):
    '''
    A context manager for doing a "deep suppression" of stdout and stderr in
    Python, i.e. will suppress all print, even if the print originates in a
    compiled C/Fortran sub-function.
       This will not suppress raised exceptions, since exceptions are printed
    to stderr just before a script exits, and after the context manager has
    exited (at least, I think that is why it lets exceptions through).

    '''
    def __init__(self):
        # Open a pair of null files
        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]
        # Save the actual stdout (1) and stderr (2) file descriptors.
        self.save_fds = (os.dup(1), os.dup(2))

    def __enter__(self):
        # Assign the null pointers to stdout and stderr.
        os.dup2(self.null_fds[0], 1)
        os.dup2(self.null_fds[1], 2)

    def __exit__(self, *_):
        # Re-assign the real stdout/stderr back to (1) and (2)
        os.dup2(self.save_fds[0], 1)
        os.dup2(self.save_fds[1], 2)
        # Close the null files
        os.close(self.null_fds[0])
        os.close(self.null_fds[1])





df=pd.read_csv(f"CaseStudyData/Episode1.csv",index_col=0)
isfailure.append(1)

df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)
with suppress_stdout_stderr():
    anomalyscores,threshold=methods.fbprophet(df,profileSize=profileSize,th=2,window_ma=window_ma)
    plt.plot(anomalyscores)
    plt.plot([threshold for asc in anomalyscores],color="red")
    plt.show()





import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import logging
logging.getLogger('fbprophet').setLevel(logging.WARNING) 
from tqdm import tqdm
import evaluation


predictions=[]
thresholds=[]
indexes=[]
isfailure=[]

profileSize=100
window_ma=0
metric="euclidean"
for episode in tqdm(range(1,21)):
    if episode<13:
        isfailure.append(1)
    else:
        isfailure.append(0)
    
    df=pd.read_csv(f"CaseStudyData/Episode{episode}.csv",index_col=0)
    isfailure.append(1)
    
    df = df.sub(df.min(axis=1), axis=0).div(df.max(axis=1) - df.min(axis=1), axis=0)
    with suppress_stdout_stderr():
        anomalyscores,threshold=methods.fbprophet(df,profileSize=profileSize,th=2,window_ma=window_ma)
        predictions.append(anomalyscores)
        thresholds.append(threshold)
        indexes.append(list(df.index[-len(anomalyscores):]))


thresholdtemp=[2 for th in thresholds]

recall,Precision,fbeta,axes=evaluation.myeval(predictions,thresholdtemp,datesofscores=indexes,PH="315",lead="26",beta=2,isfailure=isfailure,plotThem=False)
print(f"F2: AD1 {fbeta[0]},AD2 {fbeta[1]},AD3 {fbeta[2]}")
print(f"Recall: AD1 {recall[0]},AD2 {recall[1]},AD3 {recall[2]}")
print(f"Precission: {Precision}")



